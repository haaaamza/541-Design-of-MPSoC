{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T11:15:54.405997Z",
     "start_time": "2020-11-25T11:15:51.127937Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "fc1 (Dense)                  (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "relu1 (Activation)           (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "relu2 (Activation)           (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "relu3 (Activation)           (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 5)                 165       \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 4,389\n",
      "Trainable params: 4,389\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import hls4ml\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('jettag_3layer_new.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T11:16:02.227672Z",
     "start_time": "2020-11-25T11:16:02.202123Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: Dense\n",
      "  -> Activation (linear), layer name: fc1\n",
      "Layer name: relu1, layer type: Activation\n",
      "Layer name: fc2, layer type: Dense\n",
      "  -> Activation (linear), layer name: fc2\n",
      "Layer name: relu2, layer type: Activation\n",
      "Layer name: fc3, layer type: Dense\n",
      "  -> Activation (linear), layer name: fc3\n",
      "Layer name: relu3, layer type: Activation\n",
      "Layer name: output, layer type: Dense\n",
      "  -> Activation (linear), layer name: output\n",
      "Layer name: softmax, layer type: Activation\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: InputLayer, current shape: [[None, 16]]\n",
      "Layer name: fc1, layer type: Dense, current shape: [[None, 16]]\n",
      "Layer name: relu1, layer type: Activation, current shape: [[None, 64]]\n",
      "Layer name: fc2, layer type: Dense, current shape: [[None, 64]]\n",
      "Layer name: relu2, layer type: Activation, current shape: [[None, 32]]\n",
      "Layer name: fc3, layer type: Dense, current shape: [[None, 32]]\n",
      "Layer name: relu3, layer type: Activation, current shape: [[None, 32]]\n",
      "Layer name: output, layer type: Dense, current shape: [[None, 32]]\n",
      "Layer name: softmax, layer type: Softmax, current shape: [[None, 5]]\n",
      "Creating HLS model\n"
     ]
    }
   ],
   "source": [
    "#backend = hls4ml.templates.get_backend('Quartus')\n",
    "#hls_cfg = hls4ml.utils.config_from_keras_model(model, backend=backend, granularity='Model')\n",
    "hls_cfg = hls4ml.utils.config_from_keras_model(model, granularity='Model')\n",
    "hls_cfg['Model']['ReuseFactor'] = 16\n",
    "hls_cfg['Model']['Precision'] = '<16,6>'\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(model, output_dir='my-hls-test', hls_config = hls_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T11:18:06.323903Z",
     "start_time": "2020-11-25T11:18:06.284970Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['16', '6']\n",
      "['16', '6']\n",
      "['16', '6']\n",
      "['16', '6']\n",
      "['16', '6']\n",
      "['16', '6']\n",
      "['16', '6']\n",
      "['16', '6']\n",
      "['16', '6']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'latency': 96.0, 'memory': 159.6, 'dsp': 133.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "class perf_layer(object):\n",
    "    def __init__(self, name, activation, n_in, n_out, rf, precision):\n",
    "        self.name = name\n",
    "        self.activation = activation\n",
    "        self.n_in = n_in\n",
    "        self.n_out = n_out\n",
    "        self.rf = rf\n",
    "        self.bf = np.ceil(n_in*n_out/rf)\n",
    "        self.precision = [int(i) for i in precision]\n",
    "        self.estimates = {\n",
    "            'latency' : 0,\n",
    "            'memory' : 0,\n",
    "            'dsp' : 0\n",
    "        }\n",
    "        \n",
    "class pInput(perf_layer):\n",
    "    def forward_pass(self):\n",
    "        pass\n",
    "    def estimate(self):\n",
    "        self.estimates['latency'] = 5\n",
    "        self.estimates['memory'] = 0\n",
    "        self.estimates['dsp'] = 0\n",
    "    \n",
    "class pDense(perf_layer):\n",
    "    def forward_pass(self):\n",
    "        pass\n",
    "    def estimate(self):\n",
    "        self.estimates['latency'] = (5 + (self.rf-1) * 1) * np.ceil(self.precision[0] / 16)\n",
    "        self.estimates['memory'] = (self.bf / 2) * 1.2\n",
    "        self.estimates['dsp'] = self.bf / 2\n",
    "        \n",
    "class pActivation(perf_layer):\n",
    "    def forward_pass(self):\n",
    "        pass\n",
    "    def estimate(self):\n",
    "        if self.activation == 'relu':\n",
    "            self.estimates['latency'] = 0\n",
    "            self.estimates['memory'] = 0\n",
    "            self.estimates['dsp'] = 0\n",
    "        elif self.activation == 'softmax':\n",
    "            self.estimates['latency'] = 11\n",
    "            self.estimates['memory'] = 0\n",
    "            self.estimates['dsp'] =  0\n",
    "        else:\n",
    "            print(\"Activation not supported!\")\n",
    "    \n",
    "\n",
    "class perf_model(object):\n",
    "    def __init__(self, hls_model):\n",
    "        self.hls_model = hls_model\n",
    "        self.layers = []\n",
    "        \n",
    "    def add(self, layer):\n",
    "        layer_name = layer.get_attr('class_name')\n",
    "        params = (layer_name, layer.get_attr('activation'), \n",
    "                  self.get_input_size(layer), self.get_output_size(layer), \n",
    "                  layer.reuse_factor, self.get_precision(layer))\n",
    "        \n",
    "        if layer_name == 'InputLayer':\n",
    "            self.layers.append(pInput(*params)) \n",
    "        elif layer_name in ['Activation', 'Softmax']:\n",
    "            self.layers.append(pActivation(*params)) \n",
    "        elif layer_name == 'Dense':\n",
    "            self.layers.append(pDense(*params))\n",
    "        else:\n",
    "            print(\"Layer type not supported!\")\n",
    "            \n",
    "    def get_input_size(self, layer):\n",
    "        if(layer.get_attr('class_name') != 'InputLayer'):\n",
    "            return [v for k, v in layer.get_input_variable().get_shape()][0]\n",
    "        else:\n",
    "            return [v for k, v in layer.get_output_variable().get_shape()][0]\n",
    "            \n",
    "    def get_output_size(self, layer):\n",
    "        return [v for k, v in layer.get_output_variable().get_shape()][0]\n",
    "    \n",
    "    def get_precision(self, layer):\n",
    "        layer_precision = layer.get_layer_precision()\n",
    "        precision_string = [used_type for used_type in layer_precision.values()][-1].precision\n",
    "        return re.findall(r'\\d+', precision_string)\n",
    "        \n",
    "    def convert(self):\n",
    "        for layer in self.hls_model.get_layers():\n",
    "            self.add(layer)\n",
    "            \n",
    "    def print_config(self):\n",
    "        for layer in self.layers:\n",
    "            if layer.name == 'InputLayer':\n",
    "                print(f\"{layer.name} ({layer.n_in})\")\n",
    "            elif layer.name == 'Activation':\n",
    "                print(f\"{layer.activation.capitalize()} ({layer.n_in})\")\n",
    "            else:\n",
    "                print(f\"{layer.name} ({layer.n_in},{layer.n_out})\")\n",
    "                \n",
    "    def estimate_layers(self):\n",
    "        layer_estimates = []\n",
    "        for layer in self.layers:\n",
    "            layer.estimate()\n",
    "            layer_estimates.append(layer.estimatget_precisiones)\n",
    "        return layer_estimates\n",
    "    \n",
    "    def estimate_model(self):\n",
    "        model_estimate = {\n",
    "            'latency' : 0,\n",
    "            'memory' : 0,\n",
    "            'dsp' : 0\n",
    "        }\n",
    "        for layer in self.layers:\n",
    "            layer.estimate()\n",
    "            model_estimate['latency'] += layer.estimates['latency']\n",
    "            model_estimate['memory'] += layer.estimates['memory']\n",
    "            model_estimate['dsp'] += layer.estimates['dsp']\n",
    "        return model_estimate\n",
    "                \n",
    "            \n",
    "        \n",
    "pmodel = perf_model(hls_model)\n",
    "pmodel.convert()\n",
    "pmodel.estimate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T11:15:54.705228Z",
     "start_time": "2020-11-25T11:15:51.137Z"
    }
   },
   "outputs": [],
   "source": [
    "#hls_model.compile()\n",
    "#hls_model.release_dll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
